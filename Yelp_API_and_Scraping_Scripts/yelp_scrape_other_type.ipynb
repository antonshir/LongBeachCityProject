{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as url\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_id(business_id, business_review, review_date):\n",
    "    business_review = business_review.replace(\" \",\"\")\n",
    "    review_id = ''\n",
    "    if len(business_review) > 10:\n",
    "        review_id = business_id + (business_review[0:9]) + str(review_date)\n",
    "    else:\n",
    "        num_chars = 10 - len(business_review)\n",
    "        review_id = business_id + business_review + 'x' * num_chars + str(review_date)\n",
    "        \n",
    "    return review_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data):\n",
    "    with open(r'yelp_reviews_data.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_data_version_two(url):\n",
    "    \n",
    "    div_main=\"review-content\"\n",
    "    div_above_stars=\"biz-rating__stars\"\n",
    "    div_date=\"rating-qualifier\"\n",
    "    \n",
    "    one_star_div = 'i-stars i-stars--regular-1 rating-large'\n",
    "    two_star_div = 'i-stars i-stars--regular-2 rating-large'\n",
    "    three_star_div = 'i-stars i-stars--regular-3 rating-large'\n",
    "    four_star_div = 'i-stars i-stars--regular-4 rating-large'\n",
    "    five_star_div = 'i-stars i-stars--regular-5 rating-large'\n",
    "    \n",
    "    url = row[0]\n",
    "    iterations = math.ceil(int(row[2]) / 20)\n",
    "    \n",
    "    rating = ''\n",
    "    review = ''\n",
    "    review_id = ''\n",
    "    \n",
    "    counter = 0\n",
    "    web_page_incrementor = 0\n",
    "           \n",
    "    while True:\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        for divs in soup.find_all(class_=div_main):  \n",
    "            \n",
    "            row_lst = []\n",
    "            \n",
    "            review_date = (str(divs.find(class_=div_date).text).lstrip())[0:9].strip()\n",
    "            \n",
    "            if '/2019' in review_date:\n",
    "            \n",
    "                if (divs.find(class_=five_star_div))!= None:\n",
    "                    rating = 5\n",
    "\n",
    "                elif (divs.find(class_=four_star_div)) != None:\n",
    "                    rating = 4\n",
    "\n",
    "                elif (divs.find(class_=three_star_div)) != None:\n",
    "                    rating = 3\n",
    "\n",
    "                elif (divs.find(class_=two_star_div)) != None:\n",
    "                    rating = 2\n",
    "\n",
    "                else:\n",
    "                    rating = 1\n",
    "\n",
    "                review = divs.find('p').text\n",
    "                review_id = get_review_id(row[1], review, review_date)\n",
    "                \n",
    "                row_lst.append(review_id)\n",
    "                row_lst.append(row[1])\n",
    "                row_lst.append(rating)\n",
    "                row_lst.append(review_date)\n",
    "                row_lst.append(divs.find('p').text)\n",
    "                \n",
    "                write_to_csv(row_lst)\n",
    "            \n",
    "                counter += 1\n",
    "                print('row written using Version 2')\n",
    "        \n",
    "        iterations -= 1\n",
    "        \n",
    "        if counter == 0 or iterations == 0:\n",
    "            break\n",
    "        counter = 0\n",
    "        web_page_incrementor += 20\n",
    "        add_on_url = '&start=' + str(web_page_incrementor)\n",
    "        url = row[0] + add_on_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_data_version_one(row):\n",
    "    \n",
    "    main_div = \"lemon--div__373c0__1mboc sidebarActionsHoverTarget__373c0__2kfhE arrange__373c0__UHqhV gutter-12__373c0__3kguh layout-stack-small__373c0__3cHex border-color--default__373c0__2oFDT\"\n",
    "    review_div = \"lemon--p__373c0__3Qnnj text__373c0__2pB8f comment__373c0__3EKjH text-color--normal__373c0__K_MKN text-align--left__373c0__2pnx_\"\n",
    "    stars_div = \"lemon--div__373c0__1mboc i-stars__373c0__3UQrn i-stars--regular-5__373c0__3kPgP border-color--default__373c0__2oFDT overflow--hidden__373c0__8Jq2I\"     \n",
    "    date_div = \"lemon--span__373c0__3997G text__373c0__2pB8f text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_\"   \n",
    "    div_above_star=\"lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT\"\n",
    "       \n",
    "    url = row[0]\n",
    "    iterations = math.ceil(int(row[2]) / 20)\n",
    "    web_page_incrementor = 0\n",
    "    counter = 0\n",
    "    \n",
    "    rating = ''\n",
    "    review = ''\n",
    "    review_id = ''\n",
    "    \n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')                \n",
    "        \n",
    "        for divs in soup.find_all(class_=main_div):\n",
    "            \n",
    "            row_lst = []\n",
    "            review_date = review_date = divs.find(class_=date_div).text\n",
    "            \n",
    "            if '/2019' in review_date:\n",
    "                           \n",
    "                for s in (divs.find(class_=div_above_star)):\n",
    "\n",
    "                    rating = int(s['aria-label'][0])\n",
    "\n",
    "                review = divs.find(class_=review_div).text\n",
    "\n",
    "                row_lst.append(get_review_id(row[1], review, review_date))\n",
    "                row_lst.append(row[1])\n",
    "                row_lst.append(rating)\n",
    "                row_lst.append(review_date)\n",
    "                row_lst.append(review)\n",
    "\n",
    "                write_to_csv(row_lst)\n",
    "     \n",
    "                counter += 1\n",
    "                print('row written using Version 1')  \n",
    "        iterations -= 1\n",
    "        \n",
    "        if counter == 0 or iterations == 0:\n",
    "            break\n",
    "            \n",
    "        counter = 0\n",
    "        web_page_incrementor += 20\n",
    "        \n",
    "        add_on_url = '&start=' + str(web_page_incrementor)\n",
    "        url = row[0] + add_on_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_counter = 0\n",
    "header = True\n",
    "with open('for_scraping.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        if not header:\n",
    "            response = requests.get(row[0])\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "            if (soup.find_all(class_=\"review-content\")) == []:\n",
    "                get_review_data_version_one(row)\n",
    "            else:\n",
    "                get_review_data_version_two(row)\n",
    "            \n",
    "            business_counter += 1\n",
    "            \n",
    "            print(str(business_counter) + '. business is done.')\n",
    "        \n",
    "        else: \n",
    "            header = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
